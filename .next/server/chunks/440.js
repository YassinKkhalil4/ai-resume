"use strict";exports.id=440,exports.ids=[440],exports.modules={85892:(e,t,r)=>{r.d(t,{_U:()=>h,yC:()=>y});var n=r(21067);let o=n.Ry({company:n.Z_().min(1,"Company name is required"),role:n.Z_().min(1,"Role title is required"),dates:n.Z_().optional().default(""),bullets:n.IX(n.Z_().min(1,"Bullet point cannot be empty")).max(12,"Too many bullet points")}).strict(),i=n.Ry({skills_matched:n.IX(n.Z_()).optional().default([]),skills_missing_but_relevant:n.IX(n.Z_()).optional().default([]),summary:n.Z_().min(1,"Summary is required").optional().default(""),experience:n.IX(o).min(0,"Experience array is required"),skills_section:n.IX(n.Z_().min(1,"Skill cannot be empty")).min(0,"Skills array is required"),notes_to_user:n.IX(n.Z_()).optional().default([])}).strict();var s=r(57033),a=r(58276),l=r(99678);let c=`You are a resume tailoring assistant. You must never invent employment, responsibilities, or metrics not present in the user's resume.
You may rephrase and reorder text, emphasize relevant achievements, insert synonyms and role-specific keywords ONLY IF they are consistent with the original experience.
Target: ATS-friendly, concise impact bullets: Action verb + what + tools/skills + measurable outcome or scope.
Bullets must be 1–2 lines each, no first-person, no fluff.
Policy: absolutely no fabricated credentials, roles, companies, tools, or metrics.`;async function p(e,t=3){let r=null;for(let n=1;n<=t;n++)try{let t=function(e){let t=e.indexOf("{");t>0&&(e=e.substring(t));let r=e.lastIndexOf("}");return r>0&&r<e.length-1&&(e=e.substring(0,r+1)),e=e.replace(/\n/g," ").replace(/\s+/g," ").replace(/,(\s*[}\]])/g,"$1").replace(/([^\\])\\([^"\\\/bfnrt])/g,"$1\\\\$2").replace(/([^\\])\\([^"\\\/bfnrt])/g,"$1\\\\$2").replace(/"/g,'"').replace(/'/g,"'")}(e),r=JSON.parse(t),o=await m(r,n);return(0,s.Ud)(n,!0,void 0,e.length),o}catch(o){r=o,console.warn(`AI response parsing attempt ${n} failed:`,o),(0,s.Ud)(n,!1,o.message,e.length),n<t&&await new Promise(e=>setTimeout(e,1e3*n))}throw(0,s.Ud)(t,!1,r?.message,e.length),Error(`Failed to parse AI response after ${t} attempts: ${r?.message}`)}async function m(e,t){try{return i.parse(e)}catch(n){console.log(`Direct validation failed (attempt ${t}), attempting coercion:`,n);let r=function(e){let t={};return e.summary&&"string"==typeof e.summary?t.summary=e.summary.trim()||"Professional summary not available":e.summary&&"object"==typeof e.summary?t.summary=f(e.summary)||"Professional summary not available":t.summary="Professional summary not available",Array.isArray(e.skills_section)?t.skills_section=e.skills_section.filter(e=>"string"==typeof e&&e.trim().length>0).map(e=>e.trim()):e.skills_section&&"string"==typeof e.skills_section?t.skills_section=e.skills_section.split(/[,;|•\n]/).map(e=>e.trim()).filter(e=>e.length>0):e.skills&&Array.isArray(e.skills)?t.skills_section=e.skills.filter(e=>"string"==typeof e&&e.trim().length>0).map(e=>e.trim()):t.skills_section=[],Array.isArray(e.experience)?t.experience=e.experience.map(e=>u(e)).filter(Boolean):e.experience&&"object"==typeof e.experience?t.experience=[u(e.experience)].filter(Boolean):t.experience=[],t}(e);try{return i.parse(r)}catch(i){console.error("Coercion also failed:",i);let o={originalResponse:e,coercedResponse:r,validationError:n.message,coercionError:i.message,attempt:t};throw(0,s.H)(Error("Schema validation and coercion failed"),o),Error(`Schema validation failed: ${n.message}. Coercion failed: ${i.message}`)}}}function u(e){if(!e||"object"!=typeof e)return null;let t={};return"string"==typeof e.company?t.company=e.company.trim()||"Unknown Company":e.company&&"object"==typeof e.company?t.company=f(e.company)||"Unknown Company":t.company="Unknown Company","string"==typeof e.role?t.role=e.role.trim()||"Unknown Role":e.role&&"object"==typeof e.role?t.role=f(e.role)||"Unknown Role":t.role="Unknown Role",Array.isArray(e.bullets)?t.bullets=e.bullets.filter(e=>"string"==typeof e&&e.trim().length>0).map(e=>e.trim()):e.bullets&&"string"==typeof e.bullets?t.bullets=e.bullets.split(/[•\n]/).map(e=>e.trim()).filter(e=>e.length>0):e.description&&"string"==typeof e.description?t.bullets=e.description.split(/[•\n]/).map(e=>e.trim()).filter(e=>e.length>0):t.bullets=[],t}function f(e){if("string"==typeof e)return e;if("number"==typeof e)return e.toString();if(Array.isArray(e))return e.map(f).filter(Boolean).join(" ");if(e&&"object"==typeof e){for(let t of["text","content","value","description","title"])if(e[t]&&"string"==typeof e[t])return e[t];for(let[t,r]of Object.entries(e))if("string"==typeof r&&r.trim().length>0)return r}return null}async function y(e,t,r){let n=null;if(!e.experience||0===e.experience.length)return console.warn("No experience data available for tailoring, attempting extraction from free text"),await d(e,t,r);for(let o=1;o<=3;o++)try{let n=[{role:"system",content:c},{role:"user",content:function({resume_json:e,job_text:t,tone:r}){return`RESUME (STRUCTURED JSON):
${JSON.stringify(e)}

JOB DESCRIPTION:
${t}

TASKS:
1) Identify top 10 skills/keywords in the JD.
2) For each experience bullet in the resume, rewrite it to align with the JD when truthful.
3) If a bullet is irrelevant to the JD, compress or remove it.
4) Do NOT introduce new employers, roles, or fabricated metrics. If metric unknown, keep qualitative impact.
5) Return:
{
  "skills_matched": [...],
  "skills_missing_but_relevant": [...],
  "summary": "2-3 lines tailored to JD, no I/Me",
  "experience": [
    {"company": "...","role":"...","dates":"...","bullets":[ "...", "...", "..." ]},
    ...
  ],
  "skills_section": ["..."],
  "notes_to_user": ["Flagged ambiguity...", "Consider adding ... if true"]
}

TONE: ${r}
If the JOB DESCRIPTION content is very short (< 400 chars), only optimize wording and ordering; do not add any new keywords beyond what appears in the resume or JD.
Return JSON exactly in the specified schema; no extra keys.`}({resume_json:e,job_text:t,tone:r})}],i=await (0,l.P)().chat.completions.create({model:l.Y,messages:n,temperature:.2,response_format:{type:"json_object"},max_tokens:4e3}),a=i.choices[0]?.message?.content||"{}";if(!a||""===a.trim())throw Error("Empty response from AI");let m=await p(a);if(!m||"object"!=typeof m)throw Error("AI response is not a valid object");m.experience&&0!==m.experience.length||(console.warn("AI response missing experience, preserving original experience"),m.experience=e.experience||[]);let u=i.usage?.total_tokens||0;return(0,s.Ud)(o,!0,void 0,a.length),{tailored:m,tokens:u}}catch(r){n=r,console.warn(`AI request attempt ${o} failed:`,r),console.warn("Error details:",{message:r.message,stack:r.stack,originalExperienceLength:e.experience?.length||0,jdLength:t.length,attempt:o}),(0,s.Ud)(o,!1,r.message),o<3&&await new Promise(e=>setTimeout(e,1e3*Math.pow(2,o-1)))}return console.error("All AI attempts failed, returning fallback response"),console.error("Last error:",n?.message),(0,s.H)(Error("All AI attempts failed"),{original:e,jdText:t,tone:r,lastError:n?.message,attempts:3}),{tailored:g(e,t),tokens:0}}async function d(e,t,r){console.log("Handling missing experience - attempting extraction from free text");try{let n=`Extract work experience from the following resume text. Return a JSON object with an "experience" array. Each experience should have "company", "role", and "bullets" fields.

Resume text: ${JSON.stringify(e)}

Return only valid JSON.`,o=await (0,l.P)().chat.completions.create({model:l.Y,messages:[{role:"system",content:"You are an expert at extracting structured data from resume text. Return only valid JSON."},{role:"user",content:n}],temperature:.1,response_format:{type:"json_object"},max_tokens:2e3}),i=o.choices[0]?.message?.content||"{}",s=JSON.parse(i);if(s.experience&&Array.isArray(s.experience)&&s.experience.length>0)return console.log("Successfully extracted experience from free text"),await y({...e,experience:s.experience},t,r)}catch(e){console.error("Failed to extract experience from free text:",e)}return{tailored:g(e,t),tokens:0}}function g(e,t){return(0,a.Zv)(t,10),{summary:e.summary||"Experienced professional with relevant skills and experience.",skills_section:e.skills||[],experience:e.experience||[]}}async function h(e){if(!e||0===e.trim().length)return[];let t=(0,l.P)();if(!t)return console.warn("OpenAI not available for bullet extraction"),[];let r=`Given the following free-form text describing work experience, extract it into a JSON array of roles. Each role should have 'company', 'role', 'dates' (optional, can be empty string), and 'bullets' (an array of strings). If no specific role or company is clear, group related bullets under a generic "Experience" role.

Example:
Text: "Company A (2020-2022) - Software Engineer. Developed X, Implemented Y. Company B (2018-2020) - Junior Dev. Assisted with Z."
Output:
[
  {
    "company": "Company A",
    "role": "Software Engineer",
    "dates": "2020-2022",
    "bullets": ["Developed X", "Implemented Y"]
  },
  {
    "company": "Company B",
    "role": "Junior Dev",
    "dates": "2018-2020",
    "bullets": ["Assisted with Z"]
  }
]

Text: "${e}"
Output:`;try{let e=(await t.chat.completions.create({model:l.Y,messages:[{role:"user",content:r}],temperature:.2,response_format:{type:"json_object"}})).choices[0].message.content;if(!e)throw Error("AI returned an empty response for bullet extraction");let n=JSON.parse(e);if(Array.isArray(n))return n.map(e=>({company:(e.company||"").trim()||"Unknown Company",role:(e.role||"").trim()||"Unknown Role",dates:(e.dates||"").trim()||"",bullets:Array.isArray(e.bullets)?e.bullets.filter(e=>"string"==typeof e&&e.trim().length>0).map(e=>e.trim()):[]}));if(n.experience&&Array.isArray(n.experience))return n.experience.map(e=>({company:(e.company||"").trim()||"Unknown Company",role:(e.role||"").trim()||"Unknown Role",dates:(e.dates||"").trim()||"",bullets:Array.isArray(e.bullets)?e.bullets.filter(e=>"string"==typeof e&&e.trim().length>0).map(e=>e.trim()):[]}));throw Error("Unexpected response format from AI")}catch(e){return console.error("Error extracting bullets from free text:",e),(0,s.H)(e,{context:"bullet_extraction"}),[]}}},74068:(e,t,r)=>{r.d(t,{iE:()=>a,rF:()=>l});var n=r(57147),o=r.n(n);let i="/tmp/ai-resume-tailor-config.json",s={rate:{ipPerMin:Number(process.env.RATE_IP_PER_MIN||30),sessionPerMin:Number(process.env.RATE_SESSION_PER_MIN||5)},invites:(process.env.INVITE_CODES||"").split(",").map(e=>e.trim()).filter(Boolean),openaiKey:void 0,pauseTailor:!1,pauseExport:!1};function a(){return s}function l(e){s={...s,...e,rate:{...s.rate,...e.rate||{}}},function(){try{o().writeFileSync(i,JSON.stringify(s,null,2))}catch{}}()}!function(){try{if(o().existsSync(i)){let e=o().readFileSync(i,"utf8"),t=JSON.parse(e);s={...s,...t}}}catch{}}()},58276:(e,t,r)=>{function n(e,t=20){return o(e,t).all}function o(e,t=20){let r=(e||"").toLowerCase(),n=r.match(/[a-zA-Z0-9\+#\.\-]{2,}/g)||[],o=new Set(["and","the","for","with","you","our","will","are","is","to","in","of","a","an","on","as","be","by","or","we","your","this","that","at","from","preferred","requirements","responsibilities","experience"]),i={};for(let e of n)!o.has(e)&&(e.length<=2||(i[e]=(i[e]||0)+1));let s=Object.entries(i).sort((e,t)=>t[1]-e[1]).map(([e])=>e),a=["sql","python","excel","tableau","crm","react","node","aws","azure","gcp","adwords","google","facebook","paid","seo","sem","kpi","etl","ml","terraform","salesforce","hubspot","redux","typescript","next","fastapi","django","flask","java","go","kotlin","swift","figma"];for(let e of a)r.includes(e)&&!s.includes(e)&&s.unshift(e);let l=(s=Array.from(new Set(s)).slice(0,t)).filter(e=>a.includes(e)),c=s.filter(e=>!a.includes(e));return{all:s,must:l,nice:c}}r.d(t,{GI:()=>o,Zv:()=>n})},99678:(e,t,r)=>{r.d(t,{P:()=>s,Y:()=>a});var n=r(54214),o=r(74068);let i=new n.ZP({apiKey:process.env.OPENAI_API_KEY,project:process.env.OPENAI_PROJECT_ID,organization:process.env.OPENAI_ORG_ID});function s(){let e=(0,o.iE)();return e.openaiKey&&(i=new n.ZP({apiKey:e.openaiKey,project:process.env.OPENAI_PROJECT_ID,organization:process.env.OPENAI_ORG_ID})),i}let a=process.env.OPENAI_MODEL||"gpt-4o-mini"},57033:(e,t,r)=>{r.d(t,{H:()=>m,Jf:()=>f,Ud:()=>p,db:()=>c,zJ:()=>u});var n=r(57147),o=r.n(n),i=r(9576);let s="/tmp/telemetry.jsonl",a=process.env.LOG_DRAIN_URL||"",l=process.env.LOG_DRAIN_KEY||"";function c(e={}){let t=(0,i.Z)(),r=Date.now();return{id:t,end:function(n,i={}){let a={req_id:t,route:e.route||"unknown",timing:Date.now()-r,timestamp:new Date().toISOString(),final_status:n?"success":"error",...e,...i};try{o().appendFileSync(s,JSON.stringify(a)+"\n")}catch(e){console.warn("Failed to write telemetry:",e)}return y(a),a}}}function p(e,t,r,n,i){let s={timestamp:new Date().toISOString(),type:"ai_response",attempt:e,success:t,error:r?.substring(0,500),responseLength:n,model:i||process.env.OPENAI_MODEL||"gpt-4o-mini"};try{o().appendFileSync("/tmp/ai-responses.jsonl",JSON.stringify(s)+"\n")}catch(e){console.warn("Failed to log AI response:",e)}y(s)}function m(e,t={}){let r={timestamp:new Date().toISOString(),type:"error",message:e.message,stack:e.stack,context:JSON.stringify(t)};try{o().appendFileSync("/tmp/error-log.jsonl",JSON.stringify(r)+"\n")}catch(e){console.warn("Failed to log error:",e)}y(r)}function u(e,t,r,n,i){let a={timestamp:new Date().toISOString(),type:"pdf_generation",attempt:e,success:t,error:r?.substring(0,500),method:n,size:i};try{o().appendFileSync(s,JSON.stringify(a)+"\n")}catch(e){console.warn("Failed to log PDF generation:",e)}y(a)}function f(e){let t={timestamp:new Date().toISOString(),type:"request_telemetry",...e};try{o().appendFileSync(s,JSON.stringify(t)+"\n")}catch(e){console.warn("Failed to log request telemetry:",e)}y(t)}async function y(e){if(a)try{await fetch(a,{method:"POST",headers:{"Content-Type":"application/json",...l?{Authorization:`Bearer ${l}`}:{}},body:JSON.stringify(e)})}catch{}}}};